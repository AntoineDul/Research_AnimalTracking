{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Important information**\n",
        "\n",
        "This notebook was meant to run on google colab in order to use a GPU to make training faster. It will need to be refactored to run on a local machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W-vnfX2mznN"
      },
      "source": [
        "## Imports and initial checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdoir6TY74xh",
        "outputId": "0511f13e-5588-4259-f66b-7fdc3a9a75a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Apr  7 09:13:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQNydOMh9FWv",
        "outputId": "7c9f9a6b-c671-4333-b696-45e93466b5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwftdpSm9wAZ",
        "outputId": "dbcf254a-28dd-4b21-a96e-58764a8856de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.2/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "%pip install \"ultralytics<=8.3.40\" supervision roboflow\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox0Oe9AymvuD"
      },
      "source": [
        "## Get datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPVtcFmnLWah",
        "outputId": "24fb5d94-59cd-4548-f30c-ffbcfc3795ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/datasets\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Pig-detection-3 to yolov11:: 100%|██████████| 58531/58531 [00:01<00:00, 39052.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Pig-detection-3 in yolov11:: 100%|██████████| 2006/2006 [00:00<00:00, 4872.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Pig-2 to yolov11:: 100%|██████████| 58694/58694 [00:02<00:00, 21042.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Pig-2 in yolov11:: 100%|██████████| 2600/2600 [00:00<00:00, 7104.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Deteccao-Porcos-2 to yolov11:: 100%|██████████| 553393/553393 [00:08<00:00, 68659.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Deteccao-Porcos-2 in yolov11:: 100%|██████████| 2892/2892 [00:02<00:00, 1155.46it/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/datasets\n",
        "%cd {HOME}/datasets\n",
        "\n",
        "from google.colab import userdata\n",
        "from roboflow import Roboflow\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "# Dataset 1: https://universe.roboflow.com/new-workspace-fkiyn/pig-detection-cne8r\n",
        "project = rf.workspace(\"new-workspace-fkiyn\").project(\"pig-detection-cne8r\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "# Dataset 2: https://universe.roboflow.com/li-yao-tseng/pig-tilpu\n",
        "project = rf.workspace(\"li-yao-tseng\").project(\"pig-tilpu\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\")\n",
        "\n",
        "# Dataset 3: https://universe.roboflow.com/plp1/deteccao-porcos/dataset/2\n",
        "project = rf.workspace(\"plp1\").project(\"deteccao-porcos\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCvFJGz5m6lZ"
      },
      "source": [
        "## Combine datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihSoTAMvnGov"
      },
      "source": [
        "### Create new directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mtlt_6SwmU_R",
        "outputId": "c9331cd1-20c8-4ab0-fb17-040290e636b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/datasets'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y39Vi6QCmRAv"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/datasets/combined_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t5cOYVGojM4"
      },
      "source": [
        "### Separate 4th dataset in train val test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byxStoYCqbAa",
        "outputId": "c6be9c2c-fbf7-4b9f-c4a4-45c68f794d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset successfully split into train, valid, and test.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "def split_dataset(base_folder, train_ratio=0.70, valid_ratio=0.20, test_ratio=0.10, seed=42):\n",
        "    random.seed(seed)\n",
        "\n",
        "    image_folder = os.path.join(base_folder, 'train', 'images')\n",
        "    label_folder = os.path.join(base_folder, 'train', 'labels')\n",
        "\n",
        "    images = os.listdir(image_folder)\n",
        "    random.shuffle(images)  # shuffle for random split\n",
        "\n",
        "    total = len(images)\n",
        "    train_end = int(train_ratio * total)\n",
        "    valid_end = train_end + int(valid_ratio * total)\n",
        "\n",
        "    splits = {\n",
        "        'train_': images[:train_end],\n",
        "        'valid': images[train_end:valid_end],\n",
        "        'test': images[valid_end:]\n",
        "    }\n",
        "\n",
        "    for split, files in splits.items():\n",
        "        img_dst = os.path.join(base_folder, split, 'images')\n",
        "        lbl_dst = os.path.join(base_folder, split, 'labels')\n",
        "        os.makedirs(img_dst, exist_ok=True)\n",
        "        os.makedirs(lbl_dst, exist_ok=True)\n",
        "\n",
        "        for img_file in files:\n",
        "            # Copy image\n",
        "            shutil.copy(os.path.join(image_folder, img_file), os.path.join(img_dst, img_file))\n",
        "\n",
        "            # Copy label (labels has same name as image)\n",
        "            label_file = os.path.splitext(img_file)[0] + '.txt'\n",
        "            shutil.copy(os.path.join(label_folder, label_file), os.path.join(lbl_dst, label_file))\n",
        "\n",
        "    # Delete original train folder\n",
        "    shutil.rmtree(os.path.join(base_folder, 'train', 'images'))\n",
        "    shutil.rmtree(os.path.join(base_folder, 'train', 'labels'))\n",
        "    shutil.rmtree(os.path.join(base_folder, 'train'))\n",
        "\n",
        "    # Rename new train folder\n",
        "    os.rename(\"train_\", \"train\")\n",
        "\n",
        "    print(\"Dataset successfully split into train, valid, and test.\")\n",
        "\n",
        "split_dataset('Pig-detection-3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MIPlbZnI-o"
      },
      "source": [
        "### Concatenate folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTfj7J5kmpp-"
      },
      "outputs": [],
      "source": [
        "def concatenate_folders(destination_folder):\n",
        "  os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "  for dataset in ['Deteccao-Porcos-2', 'Pig-2', 'Pig-detection-3']:\n",
        "    for split in ['test', 'train', 'valid']:\n",
        "      for  folder in ['images', 'labels']:\n",
        "        os.makedirs(os.path.join(destination_folder, split, folder), exist_ok=True)\n",
        "        for file in os.listdir(os.path.join(dataset, split, folder)):\n",
        "          shutil.copy(os.path.join(dataset, split, folder, file), os.path.join(destination_folder, split, folder, file))\n",
        "\n",
        "concatenate_folders('combined_datasets')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPtpqn_dwx8I"
      },
      "source": [
        "### Create yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Qp9pk8wxDw",
        "outputId": "c91bce39-257c-4b0b-eed6-4ba71a6d1d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data.yml file created in combined_datasets\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "\n",
        "def create_data_yaml(combined_dataset_folder, num_classes, class_names):\n",
        "    # Define the paths\n",
        "    data_yaml = {\n",
        "        'train': '../train/images',\n",
        "        'val': '../valid/images',\n",
        "        'test': '../test/images',\n",
        "        'nc': num_classes,\n",
        "        'names': class_names\n",
        "    }\n",
        "\n",
        "    # Write to the YAML file\n",
        "    with open(os.path.join(combined_dataset_folder, 'data.yaml'), 'w') as yaml_file:\n",
        "        yaml.dump(data_yaml, yaml_file, default_flow_style=False)\n",
        "\n",
        "    print(\"data.yml file created in\", combined_dataset_folder)\n",
        "\n",
        "combined_dataset_folder = 'combined_datasets'\n",
        "num_classes = 1\n",
        "class_names = ['Pig']\n",
        "\n",
        "create_data_yaml(combined_dataset_folder, num_classes, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zncI2zYpziB8"
      },
      "outputs": [],
      "source": [
        "path_to_combined_datasets = '/content/datasets/combined_datasets'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eGciKojm9gS"
      },
      "source": [
        "## Train new model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ogekZbVEPQ",
        "outputId": "6fa20ff7-c5c4-4116-bf34-e10e85e3b977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.103 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.40 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11s.pt, data=/content/datasets/combined_datasets/data.yaml, epochs=6, time=None, patience=100, batch=32, imgsz=832, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744022243.313561   24743 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744022243.319959   24743 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "YOLO11s summary: 319 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
            "\n",
            "Transferred 493/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/combined_datasets/train/labels.cache... 2609 images, 1 backgrounds, 0 corrupt: 100% 2609/2609 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/datasets/combined_datasets/train/images/DALL-C2-B7E-202022-10-06-2001-35-46-20-20pigs-20eating_png.rf.3cbd4419b9a8daedda21df927c177de1.jpg: 1 duplicate labels removed\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 411, len(boxes) = 24343. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/combined_datasets/valid/labels.cache... 744 images, 0 backgrounds, 0 corrupt: 100% 744/744 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 289, len(boxes) = 7203. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 832 train, 832 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/6      14.3G      1.437      1.398      1.444        231        832: 100% 82/82 [01:31<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:13<00:00,  1.15s/it]\n",
            "                   all        744       7203      0.659      0.669      0.715      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/6        14G      1.421     0.9115      1.413        198        832: 100% 82/82 [01:30<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:13<00:00,  1.15s/it]\n",
            "                   all        744       7203      0.833      0.846      0.897      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/6      14.1G      1.378     0.8531      1.389        228        832: 100% 82/82 [01:34<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                   all        744       7203       0.82      0.806      0.868      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/6      14.2G      1.352     0.8077      1.372        364        832: 100% 82/82 [01:37<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:12<00:00,  1.05s/it]\n",
            "                   all        744       7203      0.816      0.864      0.894      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/6      14.3G      1.298     0.7388      1.336        246        832: 100% 82/82 [01:32<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:11<00:00,  1.04it/s]\n",
            "                   all        744       7203      0.896      0.884      0.938      0.579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        6/6      14.5G      1.249        0.7      1.309        279        832: 100% 82/82 [01:29<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:12<00:00,  1.02s/it]\n",
            "                   all        744       7203      0.917      0.911      0.962      0.612\n",
            "\n",
            "6 epochs completed in 0.182 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 19.2MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 19.2MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.40 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 12/12 [00:16<00:00,  1.37s/it]\n",
            "                   all        744       7203      0.916      0.911      0.962      0.612\n",
            "Speed: 0.4ms preprocess, 7.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train model=yolo11s.pt data={path_to_combined_datasets}/data.yaml epochs=6 imgsz=832 plots=True batch=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K_8Oo-d-ahAG",
        "outputId": "4c9c11c5-fd00-4795-d4ea-6820bc08113e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.40 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11s summary (fused): 238 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/combined_datasets/valid/labels.cache... 744 images, 0 backgrounds, 0 corrupt: 100% 744/744 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 289, len(boxes) = 7203. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 47/47 [00:18<00:00,  2.56it/s]\n",
            "                   all        744       7203      0.917      0.911      0.962      0.612\n",
            "Speed: 1.1ms preprocess, 12.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=val model={HOME}/datasets/runs/detect/train2/weights/best.pt data={path_to_combined_datasets}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjef__Zm4Z8k",
        "outputId": "ba146acf-71e3-408c-b5c8-4ee8d415276f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 911, in entrypoint\n",
            "    raise ValueError(f\"Invalid 'mode={mode}'. Valid modes are {MODES}.\\n{CLI_HELP_MSG}\")\n",
            "ValueError: Invalid 'mode=test'. Valid modes are {'val', 'train', 'export', 'benchmark', 'predict', 'track'}.\n",
            "\n",
            "    Arguments received: ['yolo', 'task=detect', 'mode=test', 'model=/content/datasets/runs/detect/train2/weights/best.pt', 'data=/content/datasets/combined_datasets/data.yaml']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'classify', 'segment', 'obb', 'pose', 'detect'}\n",
            "                MODE (required) is one of {'val', 'train', 'export', 'benchmark', 'predict', 'track'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Streamlit real-time webcam inference GUI\n",
            "        yolo streamlit-predict\n",
            "\n",
            "    6. Ultralytics solutions usage\n",
            "        yolo solutions count or in ['count', 'heatmap', 'queue', 'speed', 'workout', 'analytics', 'trackzone', 'help'] source=\"path/to/video/file.mp4\"\n",
            "\n",
            "    7. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "        yolo solutions help\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Solutions: https://docs.ultralytics.com/solutions/\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=test model={HOME}/datasets/runs/detect/train2/weights/best.pt data={path_to_combined_datasets}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WiCFpDrcWS1C",
        "outputId": "d7a26799-5d58-4d19-d087-ef2ea2c4c87f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_6d061893-3e0f-49f0-8f44-4d430e500699\", \"best.pt\", 19206675)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/datasets/runs/detect/train2/weights/best.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
